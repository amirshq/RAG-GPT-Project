memory:
  directory: "memory/chat_history_{}.csv"
  num_entries: 2

llm_function_caller:
  gpt_model: gpt-35-turbo-16k
  temperature: 0
  system_role:
    "As a chatbot, your goal is to respond to the user's question respectfully and concisely.\
    If the user's query can be answered by searching over the internet, return the best fuction to serve the user from the provided functions.\
    Feel free to answer the user from your own knowledge if the provided functions cannot address the query.\n\n"

llm_summarizer:
  gpt_model: gpt-35-turbo-16k
  temperature: 0
  system_role:
    "You will recieve the chat history, user's new query, along with the web search result for that query. Provide the user with the most relevant information.\n\n"

llm_rag:
  gpt_model: gpt-35-turbo-16k
  temperature: 0
  system_role:
    "You will recieve the chat history, user's new query, along with the web search result for that query on a website content. Provide the user with the most relevant information.\
    In case the user's answer does not exist in the provided content and you want to use your own knwoledge, inform the user.\n\n"

RAG:
  embedding_model_engine: "text-embedding-ada-002"
  chunk_size: 1000
  chunk_overlap: 250
  persist_directory: vectordb/
  k: 3
